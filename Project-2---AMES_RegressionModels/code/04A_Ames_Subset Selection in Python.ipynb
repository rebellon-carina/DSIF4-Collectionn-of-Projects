{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is adapted  from [here](http://www.science.smith.edu/~jcrouser/SDS293/labs/lab8-py.html?fbclid=IwAR0KyR4H9d8TWdsqWngLDzkI1J3Zqg7AV-uVgdqXTfiRYRz15PB1tb2p-d8). Would like to try how it looks like to choose best 10 fields from AMES dataset.\n",
    "\n",
    "*This lab on Subset Selection is a Python adaptation of p. 244-247 of \"Introduction to Statistical Learning with Applications in R\" by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. Adapted by R. Jordan Crouser at Smith College for SDS293: Machine Learning (Spring 2016).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Subset Selection\n",
    "\n",
    "Here we apply the best subset selection approach to the Ames housing dataset. We\n",
    "want to predict the 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>Remodel_Age</th>\n",
       "      <th>is_Remodeled</th>\n",
       "      <th>Total_SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>533352170</td>\n",
       "      <td>60</td>\n",
       "      <td>6.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>13517</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>130500</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>544</td>\n",
       "      <td>531379050</td>\n",
       "      <td>60</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11492</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2009</td>\n",
       "      <td>6.0</td>\n",
       "      <td>220000</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>535304180</td>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7922</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>109000</td>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>318</td>\n",
       "      <td>916386060</td>\n",
       "      <td>60</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9802</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>174000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1828.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>255</td>\n",
       "      <td>906425045</td>\n",
       "      <td>50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>14235</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>138500</td>\n",
       "      <td>110</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>2121.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Id        PID  MS SubClass  MS Zoning  Lot Frontage  Lot Area  \\\n",
       "0           0  109  533352170           60        6.0          79.0     13517   \n",
       "1           1  544  531379050           60        6.0          43.0     11492   \n",
       "2           2  153  535304180           20        6.0          68.0      7922   \n",
       "3           3  318  916386060           60        6.0          73.0      9802   \n",
       "4           4  255  906425045           50        6.0          82.0     14235   \n",
       "\n",
       "   Street  Lot Shape  Land Contour  ...  Pool Area  Misc Val  Mo Sold  \\\n",
       "0       2          3           2.0  ...          0         0        3   \n",
       "1       2          3           2.0  ...          0         0        4   \n",
       "2       2          4           2.0  ...          0         0        1   \n",
       "3       2          4           2.0  ...          0         0        4   \n",
       "4       2          3           2.0  ...          0         0        3   \n",
       "\n",
       "   Yr Sold  Sale Type  SalePrice  HouseAge  Remodel_Age  is_Remodeled  \\\n",
       "0     2010        6.0     130500        34           29             0   \n",
       "1     2009        6.0     220000        13            1             1   \n",
       "2     2010        6.0     109000        57           54             0   \n",
       "3     2010        6.0     174000         4            1             1   \n",
       "4     2010        6.0     138500       110           93             0   \n",
       "\n",
       "   Total_SF  \n",
       "0    2204.0  \n",
       "1    3035.0  \n",
       "2    2114.0  \n",
       "3    1828.0  \n",
       "4    2121.0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ames = pd.read_csv('../datasets/train_wfeature_all.csv')\n",
    "df_ames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1955, 82)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target\n",
    "y = df_ames['SalePrice']\n",
    "\n",
    "# Define the feature set X.\n",
    "X = df_ames.drop(columns=['Id', 'PID', 'SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform best subset selection by identifying the best model that contains a given number of predictors, where **best** is quantified using RSS (Residual Sum of Squares). We'll define a helper function to outputs the best set of variables for\n",
    "each model size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSubset(feature_set):\n",
    "    # Fit model on feature_set and calculate RSS (Residual Sum of Squares)\n",
    "    model = sm.OLS(y,X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    RSS = ((regr.predict(X[list(feature_set)]) - y) ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBest(k):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed\", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a `DataFrame` containing the best model that we generated, along with some extra information about the model. Now we want to call that function for each number of predictors $k$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 79 models on 1 predictors in 0.11440300941467285 seconds.\n",
      "Processed 3081 models on 2 predictors in 4.073864936828613 seconds.\n",
      "Processed 79079 models on 3 predictors in 127.92205810546875 seconds.\n",
      "Total elapsed time: 134.7353639602661 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Could take quite awhile to complete... and my machine cannot process more than 3!\n",
    "\n",
    "models_best = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1,4):\n",
    "    models_best.loc[i] = getBest(i)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have one  `DataFrame` that contains the best models we've generated along with their RSS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RSS</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.709225e+12</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.712291e+12</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.413885e+12</td>\n",
       "      <td>&lt;statsmodels.regression.linear_model.Regressio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RSS                                              model\n",
       "1  2.709225e+12  <statsmodels.regression.linear_model.Regressio...\n",
       "2  1.712291e+12  <statsmodels.regression.linear_model.Regressio...\n",
       "3  1.413885e+12  <statsmodels.regression.linear_model.Regressio..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to access the details of each model, no problem! We can get a full rundown of a single model using the `summary()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:              SalePrice   R-squared (uncentered):                   0.957\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.957\n",
      "Method:                 Least Squares   F-statistic:                          4.391e+04\n",
      "Date:                Mon, 31 Jan 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        19:49:15   Log-Likelihood:                         -23350.\n",
      "No. Observations:                1955   AIC:                                  4.670e+04\n",
      "Df Residuals:                    1954   BIC:                                  4.671e+04\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Total_SF      68.9346      0.329    209.541      0.000      68.289      69.580\n",
      "==============================================================================\n",
      "Omnibus:                       74.828   Durbin-Watson:                   2.028\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              165.526\n",
      "Skew:                          -0.222   Prob(JB):                     1.14e-36\n",
      "Kurtosis:                       4.354   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(models_best.loc[1, \"model\"].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than letting the results of our call to the `summary()` function print to the screen, we can access just the parts we need using the model's attributes. For example, if we want the $R^2$ value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977764483210051"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_best.loc[3, \"model\"].rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! In addition to the verbose output we get when we print the summary to the screen, fitting the `OLM` also produced many other useful statistics such as adjusted $R^2$, AIC, and BIC. We can examine these to try to select the best overall model. Let's start by looking at $R^2$ across all our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.957393\n",
       "2    0.973072\n",
       "3    0.977764\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets the second element from each row ('model') and pulls out its rsquared attribute\n",
    "models_best.apply(lambda row: row[1].rsquared, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the $R^2$ statistic increases monotonically as more\n",
    "variables are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward and Backward Stepwise Selection\n",
    "We can also use a similar approach to perform forward stepwise\n",
    "or backward stepwise selection, using a slight modification of the functions we defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(predictors):\n",
    "\n",
    "    # Pull out predictors we still need to process\n",
    "    remaining_predictors = [p for p in X.columns if p not in predictors]\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for p in remaining_predictors:\n",
    "        results.append(processSubset(predictors+[p]))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how much faster it runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  79 models on 1 predictors in 0.1184239387512207 seconds.\n",
      "Processed  78 models on 2 predictors in 0.1374368667602539 seconds.\n",
      "Processed  77 models on 3 predictors in 0.14483308792114258 seconds.\n",
      "Processed  76 models on 4 predictors in 0.157761812210083 seconds.\n",
      "Processed  75 models on 5 predictors in 0.14637970924377441 seconds.\n",
      "Processed  74 models on 6 predictors in 0.14864015579223633 seconds.\n",
      "Processed  73 models on 7 predictors in 0.1542372703552246 seconds.\n",
      "Processed  72 models on 8 predictors in 0.15868091583251953 seconds.\n",
      "Processed  71 models on 9 predictors in 0.16311216354370117 seconds.\n",
      "Processed  70 models on 10 predictors in 0.17609000205993652 seconds.\n",
      "Processed  69 models on 11 predictors in 0.18184518814086914 seconds.\n",
      "Processed  68 models on 12 predictors in 0.16529011726379395 seconds.\n",
      "Processed  67 models on 13 predictors in 0.16923999786376953 seconds.\n",
      "Processed  66 models on 14 predictors in 0.17212224006652832 seconds.\n",
      "Processed  65 models on 15 predictors in 0.18011808395385742 seconds.\n",
      "Processed  64 models on 16 predictors in 0.1953582763671875 seconds.\n",
      "Processed  63 models on 17 predictors in 0.21117591857910156 seconds.\n",
      "Processed  62 models on 18 predictors in 0.21524977684020996 seconds.\n",
      "Processed  61 models on 19 predictors in 0.20678210258483887 seconds.\n",
      "Processed  60 models on 20 predictors in 0.19028091430664062 seconds.\n",
      "Processed  59 models on 21 predictors in 0.1982560157775879 seconds.\n",
      "Processed  58 models on 22 predictors in 0.2033841609954834 seconds.\n",
      "Processed  57 models on 23 predictors in 0.2059028148651123 seconds.\n",
      "Processed  56 models on 24 predictors in 0.20564985275268555 seconds.\n",
      "Processed  55 models on 25 predictors in 0.23498177528381348 seconds.\n",
      "Processed  54 models on 26 predictors in 0.22820281982421875 seconds.\n",
      "Processed  53 models on 27 predictors in 0.24275469779968262 seconds.\n",
      "Processed  52 models on 28 predictors in 0.22459793090820312 seconds.\n",
      "Processed  51 models on 29 predictors in 0.2328929901123047 seconds.\n",
      "Processed  50 models on 30 predictors in 0.2381441593170166 seconds.\n",
      "Processed  49 models on 31 predictors in 0.24425125122070312 seconds.\n",
      "Processed  48 models on 32 predictors in 0.24141836166381836 seconds.\n",
      "Processed  47 models on 33 predictors in 0.23853588104248047 seconds.\n",
      "Processed  46 models on 34 predictors in 0.25103116035461426 seconds.\n",
      "Processed  45 models on 35 predictors in 0.21853017807006836 seconds.\n",
      "Processed  44 models on 36 predictors in 0.25444602966308594 seconds.\n",
      "Processed  43 models on 37 predictors in 0.24036812782287598 seconds.\n",
      "Processed  42 models on 38 predictors in 0.21987199783325195 seconds.\n",
      "Processed  41 models on 39 predictors in 0.2198657989501953 seconds.\n",
      "Processed  40 models on 40 predictors in 0.22619009017944336 seconds.\n",
      "Processed  39 models on 41 predictors in 0.23384809494018555 seconds.\n",
      "Processed  38 models on 42 predictors in 0.22917699813842773 seconds.\n",
      "Processed  37 models on 43 predictors in 0.22942781448364258 seconds.\n",
      "Processed  36 models on 44 predictors in 0.22579097747802734 seconds.\n",
      "Processed  35 models on 45 predictors in 0.22523117065429688 seconds.\n",
      "Processed  34 models on 46 predictors in 0.2201390266418457 seconds.\n",
      "Processed  33 models on 47 predictors in 0.23451638221740723 seconds.\n",
      "Processed  32 models on 48 predictors in 0.21335983276367188 seconds.\n",
      "Processed  31 models on 49 predictors in 0.20974302291870117 seconds.\n",
      "Processed  30 models on 50 predictors in 0.20828890800476074 seconds.\n",
      "Processed  29 models on 51 predictors in 0.2007291316986084 seconds.\n",
      "Processed  28 models on 52 predictors in 0.18772315979003906 seconds.\n",
      "Processed  27 models on 53 predictors in 0.19896483421325684 seconds.\n",
      "Processed  26 models on 54 predictors in 0.19720196723937988 seconds.\n",
      "Processed  25 models on 55 predictors in 0.19519805908203125 seconds.\n",
      "Processed  24 models on 56 predictors in 0.1912999153137207 seconds.\n",
      "Processed  23 models on 57 predictors in 0.1893312931060791 seconds.\n",
      "Processed  22 models on 58 predictors in 0.19112110137939453 seconds.\n",
      "Processed  21 models on 59 predictors in 0.18246793746948242 seconds.\n",
      "Processed  20 models on 60 predictors in 0.17020297050476074 seconds.\n",
      "Processed  19 models on 61 predictors in 0.16589903831481934 seconds.\n",
      "Processed  18 models on 62 predictors in 0.15764403343200684 seconds.\n",
      "Processed  17 models on 63 predictors in 0.15063118934631348 seconds.\n",
      "Processed  16 models on 64 predictors in 0.14053821563720703 seconds.\n",
      "Processed  15 models on 65 predictors in 0.14113688468933105 seconds.\n",
      "Processed  14 models on 66 predictors in 0.12642383575439453 seconds.\n",
      "Processed  13 models on 67 predictors in 0.12421607971191406 seconds.\n",
      "Processed  12 models on 68 predictors in 0.11396598815917969 seconds.\n",
      "Processed  11 models on 69 predictors in 0.1158902645111084 seconds.\n",
      "Processed  10 models on 70 predictors in 0.10396003723144531 seconds.\n",
      "Processed  9 models on 71 predictors in 0.09325599670410156 seconds.\n",
      "Processed  8 models on 72 predictors in 0.08295822143554688 seconds.\n",
      "Processed  7 models on 73 predictors in 0.07415604591369629 seconds.\n",
      "Processed  6 models on 74 predictors in 0.06340503692626953 seconds.\n",
      "Processed  5 models on 75 predictors in 0.05312490463256836 seconds.\n",
      "Processed  4 models on 76 predictors in 0.04470086097717285 seconds.\n",
      "Processed  3 models on 77 predictors in 0.033824920654296875 seconds.\n",
      "Processed  2 models on 78 predictors in 0.023328065872192383 seconds.\n",
      "Processed  1 models on 79 predictors in 0.012660980224609375 seconds.\n",
      "Total elapsed time: 14.32231593132019 seconds.\n"
     ]
    }
   ],
   "source": [
    "models_fwd = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "predictors = []\n",
    "\n",
    "for i in range(1,len(X.columns)+1):    \n",
    "    models_fwd.loc[i] = forward(predictors)\n",
    "    predictors = models_fwd.loc[i][\"model\"].model.exog_names\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew! That's a lot better. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:              SalePrice   R-squared (uncentered):                   0.957\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.957\n",
      "Method:                 Least Squares   F-statistic:                          4.391e+04\n",
      "Date:                Mon, 31 Jan 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        19:49:30   Log-Likelihood:                         -23350.\n",
      "No. Observations:                1955   AIC:                                  4.670e+04\n",
      "Df Residuals:                    1954   BIC:                                  4.671e+04\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Total_SF      68.9346      0.329    209.541      0.000      68.289      69.580\n",
      "==============================================================================\n",
      "Omnibus:                       74.828   Durbin-Watson:                   2.028\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              165.526\n",
      "Skew:                          -0.222   Prob(JB):                     1.14e-36\n",
      "Kurtosis:                       4.354   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:              SalePrice   R-squared (uncentered):                   0.973\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.973\n",
      "Method:                 Least Squares   F-statistic:                          3.529e+04\n",
      "Date:                Mon, 31 Jan 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        19:49:30   Log-Likelihood:                         -22901.\n",
      "No. Observations:                1955   AIC:                                  4.581e+04\n",
      "Df Residuals:                    1953   BIC:                                  4.582e+04\n",
      "Df Model:                           2                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Total_SF        48.5131      0.660     73.539      0.000      47.219      49.807\n",
      "Neighborhood  3789.6433    112.384     33.721      0.000    3569.239    4010.048\n",
      "==============================================================================\n",
      "Omnibus:                       75.640   Durbin-Watson:                   2.004\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              208.219\n",
      "Skew:                           0.112   Prob(JB):                     6.11e-46\n",
      "Kurtosis:                       4.583   Cond. No.                         430.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(models_fwd.loc[1, \"model\"].summary())\n",
    "print(models_fwd.loc[2, \"model\"].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that using forward stepwise selection, the best one-variable\n",
    "model contains only `Hits`, and the best two-variable model additionally\n",
    "includes `CRBI`. Let's see how the models stack up against best subset selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:              SalePrice   R-squared (uncentered):                   0.986\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.986\n",
      "Method:                 Least Squares   F-statistic:                          1.405e+04\n",
      "Date:                Mon, 31 Jan 2022   Prob (F-statistic):                        0.00\n",
      "Time:                        19:49:30   Log-Likelihood:                         -22237.\n",
      "No. Observations:                1955   AIC:                                  4.449e+04\n",
      "Df Residuals:                    1945   BIC:                                  4.455e+04\n",
      "Df Model:                          10                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Total_SF        38.5703      1.034     37.320      0.000      36.543      40.597\n",
      "Neighborhood  1339.7600    108.990     12.292      0.000    1126.010    1553.510\n",
      "Overall Qual  9833.1533    603.226     16.301      0.000    8650.115     1.1e+04\n",
      "Land Slope   -1.976e+04   1185.091    -16.677      0.000   -2.21e+04   -1.74e+04\n",
      "Bsmt Unf SF    -18.1895      1.234    -14.734      0.000     -20.611     -15.768\n",
      "Kitchen Qual  1.038e+04   1010.537     10.270      0.000    8396.141    1.24e+04\n",
      "Garage Area     26.7666      2.968      9.018      0.000      20.946      32.587\n",
      "Fireplace Qu  3105.8100    312.524      9.938      0.000    2492.892    3718.728\n",
      "HouseAge      -303.8344     24.270    -12.519      0.000    -351.432    -256.237\n",
      "Overall Cond  4482.4381    471.690      9.503      0.000    3557.367    5407.509\n",
      "==============================================================================\n",
      "Omnibus:                      120.207   Durbin-Watson:                   1.923\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              446.165\n",
      "Skew:                           0.179   Prob(JB):                     1.31e-97\n",
      "Kurtosis:                       5.313   Cond. No.                     7.31e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 7.31e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#print(models_best.loc[6, \"model\"].summary())\n",
    "print(models_fwd.loc[10, \"model\"].summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For this data, the best one-variable through six-variable\n",
    "models are each identical for best subset and forward selection.\n",
    "\n",
    "# Backward Selection\n",
    "Not much has to change to implement backward selection... just looping through the predictors in reverse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(predictors):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for combo in itertools.combinations(predictors, len(predictors)-1):\n",
    "        results.append(processSubset(combo))\n",
    "    \n",
    "    # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    \n",
    "    # Choose the model with the highest RSS\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    \n",
    "    toc = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)-1, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    \n",
    "    # Return the best model, along with some other useful information about the model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  79 models on 78 predictors in 0.9147520065307617 seconds.\n",
      "Processed  78 models on 77 predictors in 0.8924548625946045 seconds.\n",
      "Processed  77 models on 76 predictors in 0.8668673038482666 seconds.\n",
      "Processed  76 models on 75 predictors in 0.8502919673919678 seconds.\n",
      "Processed  75 models on 74 predictors in 0.7982358932495117 seconds.\n",
      "Processed  74 models on 73 predictors in 0.795745849609375 seconds.\n",
      "Processed  73 models on 72 predictors in 0.7497646808624268 seconds.\n",
      "Processed  72 models on 71 predictors in 0.725208044052124 seconds.\n",
      "Processed  71 models on 70 predictors in 0.6973659992218018 seconds.\n",
      "Processed  70 models on 69 predictors in 0.6804258823394775 seconds.\n",
      "Processed  69 models on 68 predictors in 0.6786031723022461 seconds.\n",
      "Processed  68 models on 67 predictors in 0.6806380748748779 seconds.\n",
      "Processed  67 models on 66 predictors in 0.6637217998504639 seconds.\n",
      "Processed  66 models on 65 predictors in 0.628868818283081 seconds.\n",
      "Processed  65 models on 64 predictors in 0.6710240840911865 seconds.\n",
      "Processed  64 models on 63 predictors in 0.6118190288543701 seconds.\n",
      "Processed  63 models on 62 predictors in 0.5862526893615723 seconds.\n",
      "Processed  62 models on 61 predictors in 0.5623738765716553 seconds.\n",
      "Processed  61 models on 60 predictors in 0.5520939826965332 seconds.\n",
      "Processed  60 models on 59 predictors in 0.5144000053405762 seconds.\n",
      "Processed  59 models on 58 predictors in 0.5048537254333496 seconds.\n",
      "Processed  58 models on 57 predictors in 0.48842597007751465 seconds.\n",
      "Processed  57 models on 56 predictors in 0.45595288276672363 seconds.\n",
      "Processed  56 models on 55 predictors in 0.4366719722747803 seconds.\n",
      "Processed  55 models on 54 predictors in 0.4273958206176758 seconds.\n",
      "Processed  54 models on 53 predictors in 0.41184377670288086 seconds.\n",
      "Processed  53 models on 52 predictors in 0.4024949073791504 seconds.\n",
      "Processed  52 models on 51 predictors in 0.38912487030029297 seconds.\n",
      "Processed  51 models on 50 predictors in 0.36513710021972656 seconds.\n",
      "Processed  50 models on 49 predictors in 0.35193824768066406 seconds.\n",
      "Processed  49 models on 48 predictors in 0.3416740894317627 seconds.\n",
      "Processed  48 models on 47 predictors in 0.33413195610046387 seconds.\n",
      "Processed  47 models on 46 predictors in 0.34053921699523926 seconds.\n",
      "Processed  46 models on 45 predictors in 0.36364293098449707 seconds.\n",
      "Processed  45 models on 44 predictors in 0.36254191398620605 seconds.\n",
      "Processed  44 models on 43 predictors in 0.3346281051635742 seconds.\n",
      "Processed  43 models on 42 predictors in 0.3002889156341553 seconds.\n",
      "Processed  42 models on 41 predictors in 0.2901761531829834 seconds.\n",
      "Processed  41 models on 40 predictors in 0.2732558250427246 seconds.\n",
      "Processed  40 models on 39 predictors in 0.26686787605285645 seconds.\n",
      "Processed  39 models on 38 predictors in 0.25647735595703125 seconds.\n",
      "Processed  38 models on 37 predictors in 0.23816895484924316 seconds.\n",
      "Processed  37 models on 36 predictors in 0.2203068733215332 seconds.\n",
      "Processed  36 models on 35 predictors in 0.21395301818847656 seconds.\n",
      "Processed  35 models on 34 predictors in 0.20137333869934082 seconds.\n",
      "Processed  34 models on 33 predictors in 0.19593501091003418 seconds.\n",
      "Processed  33 models on 32 predictors in 0.18668389320373535 seconds.\n",
      "Processed  32 models on 31 predictors in 0.17259788513183594 seconds.\n",
      "Processed  31 models on 30 predictors in 0.16368579864501953 seconds.\n",
      "Processed  30 models on 29 predictors in 0.15160107612609863 seconds.\n",
      "Processed  29 models on 28 predictors in 0.14526724815368652 seconds.\n",
      "Processed  28 models on 27 predictors in 0.13283610343933105 seconds.\n",
      "Processed  27 models on 26 predictors in 0.1265089511871338 seconds.\n",
      "Processed  26 models on 25 predictors in 0.11930203437805176 seconds.\n",
      "Processed  25 models on 24 predictors in 0.10791707038879395 seconds.\n",
      "Processed  24 models on 23 predictors in 0.10304784774780273 seconds.\n",
      "Processed  23 models on 22 predictors in 0.10056805610656738 seconds.\n",
      "Processed  22 models on 21 predictors in 0.09775471687316895 seconds.\n",
      "Processed  21 models on 20 predictors in 0.08344197273254395 seconds.\n",
      "Processed  20 models on 19 predictors in 0.07270598411560059 seconds.\n",
      "Processed  19 models on 18 predictors in 0.07664680480957031 seconds.\n",
      "Processed  18 models on 17 predictors in 0.06517577171325684 seconds.\n",
      "Processed  17 models on 16 predictors in 0.05613899230957031 seconds.\n",
      "Processed  16 models on 15 predictors in 0.05023908615112305 seconds.\n",
      "Processed  15 models on 14 predictors in 0.04420971870422363 seconds.\n",
      "Processed  14 models on 13 predictors in 0.04173994064331055 seconds.\n",
      "Processed  13 models on 12 predictors in 0.03827214241027832 seconds.\n",
      "Processed  12 models on 11 predictors in 0.03569197654724121 seconds.\n",
      "Processed  11 models on 10 predictors in 0.039916038513183594 seconds.\n",
      "Processed  10 models on 9 predictors in 0.033219099044799805 seconds.\n",
      "Processed  9 models on 8 predictors in 0.02294921875 seconds.\n",
      "Processed  8 models on 7 predictors in 0.018980741500854492 seconds.\n",
      "Processed  7 models on 6 predictors in 0.015962839126586914 seconds.\n",
      "Processed  6 models on 5 predictors in 0.01371908187866211 seconds.\n",
      "Processed  5 models on 4 predictors in 0.011214971542358398 seconds.\n",
      "Processed  4 models on 3 predictors in 0.00919198989868164 seconds.\n",
      "Processed  3 models on 2 predictors in 0.006825923919677734 seconds.\n",
      "Processed  2 models on 1 predictors in 0.004826068878173828 seconds.\n",
      "Total elapsed time: 25.751192092895508 seconds.\n"
     ]
    }
   ],
   "source": [
    "models_bwd = pd.DataFrame(columns=[\"RSS\", \"model\"], index = range(1,len(X.columns)))\n",
    "\n",
    "tic = time.time()\n",
    "predictors = X.columns\n",
    "\n",
    "while(len(predictors) > 1):  \n",
    "    models_bwd.loc[len(predictors)-1] = backward(predictors)\n",
    "    predictors = models_bwd.loc[len(predictors)-1][\"model\"].model.exog_names\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the Best 3 features for each, if they are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Best Subset:\n",
      "------------\n",
      "Overall Qual    14666.284348\n",
      "HouseAge         -511.367425\n",
      "Total_SF           41.371441\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"------------\")\n",
    "print(\"Best Subset:\")\n",
    "print(\"------------\")\n",
    "print(models_best.loc[3, \"model\"].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Foward Selection:\n",
      "-----------------\n",
      "Total_SF          32.034526\n",
      "Neighborhood    3026.681158\n",
      "Overall Qual    8820.995273\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------\")\n",
    "print(\"Foward Selection:\")\n",
    "print(\"-----------------\")\n",
    "print(models_fwd.loc[3, \"model\"].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Backward Selection:\n",
      "-------------------\n",
      "Neighborhood    3026.681158\n",
      "Overall Qual    8820.995273\n",
      "Total_SF          32.034526\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------\")\n",
    "print(\"Backward Selection:\")\n",
    "print(\"-------------------\")\n",
    "print(models_bwd.loc[3, \"model\"].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All are the same for Best 3 Features. For Best 10, we can check only the backward and forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Foward Selection:\n",
      "-----------------\n",
      "Total_SF           38.570278\n",
      "Neighborhood     1339.760030\n",
      "Overall Qual     9833.153253\n",
      "Land Slope     -19763.454812\n",
      "Bsmt Unf SF       -18.189519\n",
      "Kitchen Qual    10377.989723\n",
      "Garage Area        26.766579\n",
      "Fireplace Qu     3105.809960\n",
      "HouseAge         -303.834379\n",
      "Overall Cond     4482.438133\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"-----------------\")\n",
    "print(\"Foward Selection:\")\n",
    "print(\"-----------------\")\n",
    "print(models_fwd.loc[10, \"model\"].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Backward Selection:\n",
      "-------------------\n",
      "MS SubClass       -117.413648\n",
      "Neighborhood      1619.774714\n",
      "Overall Qual     11701.119206\n",
      "Overall Cond      4933.075416\n",
      "Year Built         290.345792\n",
      "BsmtFin SF 1        23.490328\n",
      "Total Bsmt SF      -38.031246\n",
      "Kitchen Qual     11838.047131\n",
      "Yr Sold           -325.104034\n",
      "Total_SF            51.262003\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------------\")\n",
    "print(\"Backward Selection:\")\n",
    "print(\"-------------------\")\n",
    "print(models_bwd.loc[10, \"model\"].params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look different. I will combine these and try the best 10 of Forward and Backward subset using the function model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 15 models on 1 predictors in 0.03155088424682617 seconds.\n",
      "Processed 105 models on 2 predictors in 0.16662311553955078 seconds.\n",
      "Processed 455 models on 3 predictors in 0.7221801280975342 seconds.\n",
      "Processed 1365 models on 4 predictors in 2.1253740787506104 seconds.\n",
      "Processed 3003 models on 5 predictors in 5.417328834533691 seconds.\n",
      "Processed 5005 models on 6 predictors in 10.190083980560303 seconds.\n",
      "Processed 6435 models on 7 predictors in 14.373605966567993 seconds.\n",
      "Processed 6435 models on 8 predictors in 14.485986948013306 seconds.\n",
      "Processed 5005 models on 9 predictors in 12.182610034942627 seconds.\n",
      "Processed 3003 models on 10 predictors in 7.887772798538208 seconds.\n",
      "Total elapsed time: 68.95857119560242 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Should be quicker as we have less features than the original\n",
    "#15 unique features\n",
    "\n",
    "X = df_ames[['Total_SF', 'Neighborhood','Overall Qual','Land Slope','Bsmt Unf SF','Kitchen Qual',\n",
    "            'Garage Area','Fireplace Qu','HouseAge','Overall Cond','Yr Sold','Total Bsmt SF','BsmtFin SF 1',\n",
    "            'Year Built', 'MS SubClass']]\n",
    "models_best = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "\n",
    "tic = time.time()\n",
    "for i in range(1,11):\n",
    "    models_best.loc[i] = getBest(i)\n",
    "\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Best Subset:\n",
      "------------\n",
      "Total_SF           39.724766\n",
      "Neighborhood     1471.621870\n",
      "Overall Qual     9999.805385\n",
      "Bsmt Unf SF       -19.722646\n",
      "Kitchen Qual    11849.345263\n",
      "Garage Area        27.314289\n",
      "Fireplace Qu     2997.425554\n",
      "Overall Cond     4979.112681\n",
      "Yr Sold          -281.931927\n",
      "Year Built        245.409920\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"------------\")\n",
    "print(\"Best Subset:\")\n",
    "print(\"------------\")\n",
    "print(models_best.loc[10, \"model\"].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
