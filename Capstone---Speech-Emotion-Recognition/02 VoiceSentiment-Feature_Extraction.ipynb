{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96a49311",
   "metadata": {},
   "source": [
    "## Feature Extraction Using Librosa\n",
    "\n",
    "1. Load the datasets\n",
    "    - 1.1 Combine 3 datasets listed below and label with corresponding emotions\n",
    "    - 1.2 Extract Features\n",
    "        - 2.1 For Train data, there will be data augmentation, adding noise and pitch\n",
    "        - 2.2 For Test data, extract librosa features\n",
    "\n",
    "2. Features to be extracted:\n",
    "    - 2.1. Root Mean Square\n",
    "    - 2.2 Spectral Centroid\n",
    "    - 2.3. Spectral Rolloff\n",
    "    - 2.4. Zero Crossing Rate\n",
    "    - 2.5. Chroma STFT\n",
    "    - 2.6. MFCC\n",
    "    - 2.7. Mel Spectogram\n",
    "\n",
    "There  will be 184 features to be saved in test.csv and train.csv\n",
    "\n",
    "#### SOURCE\n",
    "[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)](https://zenodo.org/record/1188976#.YmlBpS8RoTs)\n",
    "[Toronto emotional speech set (TESS)](https://tspace.library.utoronto.ca/handle/1807/24487)\n",
    "[Surrey Audio-Visual Expressed Emotion (SAVEE)Database](http://personal.ee.surrey.ac.uk/Personal/P.Jackson/SAVEE/Database.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d70b0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#to list the files\n",
    "from glob import glob\n",
    "\n",
    "#for Audio processing\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6ab6f8",
   "metadata": {},
   "source": [
    "### 01. Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df39996f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir):\n",
    "    \n",
    "    files = glob(dir + '*/*.wav')\n",
    "    print(f\"{dir} file counts : \", len(files))\n",
    "        \n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632f248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the directories/paths\n",
    "ravdess_rootdir = './raw_source/RAVDESS/'\n",
    "tess_rootdir = './raw_source/TESS/'\n",
    "savee_rootdir = './raw_source/Savee/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc9ddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./raw_source/RAVDESS/ file counts :  1440\n",
      "./raw_source/TESS/ file counts :  2800\n",
      "./raw_source/Savee/ file counts :  480\n"
     ]
    }
   ],
   "source": [
    "#get the files for each collection\n",
    "ravdess = get_files(ravdess_rootdir)\n",
    "tess =  get_files(tess_rootdir)\n",
    "savee =  get_files(savee_rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42e74373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the mapping for RAVDEE dataset, map the label into actual emotions or descriptions for easy analysis\n",
    "\n",
    "dict_emotion = {\n",
    "    \n",
    "    \"01\" : \"neutral\", \n",
    "    \"02\" : \"calm\", \n",
    "    \"03\" : \"happy\",\n",
    "    \"04\" : \"sad\",\n",
    "    \"05\" : \"angry\",\n",
    "    \"06\" : \"fear\",\n",
    "    \"07\" : \"disgust\", \n",
    "    \"08\" : \"surprised\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dac94be",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = []\n",
    "file = []\n",
    "audio = []\n",
    "source = []\n",
    "\n",
    "#RAVDESS dataset, extract the emotion from filename\n",
    "for r in ravdess:\n",
    "    file.append(r)\n",
    "    \n",
    "    #save the audio\n",
    "    data, _ = librosa.load(r)\n",
    "    \n",
    "    #get the emotion part\n",
    "    emotion.append(dict_emotion[r.split(\"-\")[2]])\n",
    "    audio.append(data)\n",
    "    source.append('ravdess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "180add5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESS dataset, extract the emotion from filename\n",
    "\n",
    "for t in tess:\n",
    "    \n",
    "    file.append(t)\n",
    "    \n",
    "    #save the audio\n",
    "    data, _ = librosa.load(t)\n",
    "    \n",
    "    #get the emotion part\n",
    "    emo = t.split(\"_\")[-1].split(\".\")[0]\n",
    "    \n",
    "    if emo == \"ps\":\n",
    "        emo = \"surprised\"\n",
    "        \n",
    "    emotion.append(emo)\n",
    "    audio.append(data)\n",
    "    source.append('tess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780d8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVEE dataset, extract the emotion from filename\n",
    "\n",
    "for s in savee:\n",
    "    \n",
    "    file.append(s)\n",
    "    \n",
    "    #save the audio\n",
    "    data, _ = librosa.load(s)\n",
    "    \n",
    "    filename= s.split('/')\n",
    "    label = filename[4]\n",
    "    \n",
    "    if label[0] == 'a':\n",
    "        emotion.append('angry')\n",
    "    elif label[0] == 'd':\n",
    "        emotion.append('disgust')\n",
    "    elif label[0] == 'f':\n",
    "        emotion.append('fear')\n",
    "    elif label[0] == 'h':\n",
    "        emotion.append('happy')\n",
    "    elif label[0] == 'n':\n",
    "        emotion.append('neutral')\n",
    "    elif label[0:2] == 'sa':\n",
    "        emotion.append('sad')\n",
    "    elif label[0:2] == 'su':\n",
    "        emotion.append('surprised')\n",
    "    else:\n",
    "         emotion.append('unknown')\n",
    "            \n",
    "    audio.append(data)\n",
    "    source.append('savee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7651f6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataframe\n",
    "data = {'file':file, \n",
    "        'emotion':emotion,\n",
    "        'audio':audio,\n",
    "        'source': source}\n",
    "df_all = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae2186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4720, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total \n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d255e0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, ' Count by Emotions')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFNCAYAAACuWnPfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAgoUlEQVR4nO3de7gddX3v8fcHEPDKRQIiAYOaVkErlpSKtt6whWNVqIUaKxaslXoO3traHmhty9Gm5bS1p1akFq0Sb8WoVSLto2AUrFcMikBAhHKNIASUKqJR4Hv+mF9kkeydbDZZ+7eT/X49z37WrN+ay3d+WWvWJzOzZlJVSJIkqZ9tehcgSZI01xnIJEmSOjOQSZIkdWYgkyRJ6sxAJkmS1JmBTJIkqTMDmaStUpKTkryvdx33V5K3J/mz3nVIGi8DmaRpy+A1SS5J8oMkq5N8KMkTx7zcBUkqyXbjXM7I8q5J8sMkt4/8nTKG5Ryb5HOjbVX1yqp60+ZelqTZZUY2ZpK2Wm8Bfg14BfB5YFvg11vbxR3rGofnV9WnehchaevkHjJJ05JkIXA88OKq+nRVra2qO6rq/VV1chtnpyTvSbImybVJ3pBkm/bavQ4prr/XK8m5Sd6U5PNJvp/k7CS7tdE/2x5va3urDp6kzB2TfLBN/9UkT2rz/qMkH1lvfd6a5B+m0Q/Hthr/X5LbklyV5Kmt/fokNyc5ZmT8CfskyeOBtwMHt3W6rY1/epK/HJn+FUmuTPKdJMuTPHLktUryyiRXJPlukrclSXvtsUnOS/LfSW5J8sH7uq6SxsdAJmm6DgFWV9X5GxnnrcBOwKOBZwC/DbzsPizjt9r4uwPbA69v7U9vjztX1UOq6ouTTH848CFgV+ADwMeSPAB4H3BYkp0BWgh8EfDe+1DbqF8ELgIe3pZzBvALwGOBo4FTkjykjTthn1TVZcArgS+2ddp5/YUkeTbw18BvAnsC17ZljXpeW/aT2niHtvY3AWcDuwDzWx2SZgkDmaTpejhw42QvJtmWIeScWFXfr6prgDcDL70Py3h3VX2zqn4ILAMOuI81XlBVH66qnwB/D+wIPKWqbmTYy3ZUG+8w4JaqumAj8/pY2wO27u8VI69dXVXvrqq7gA8CewNvbHsNzwZ+DDx2M/TJS4B3VdVXq2otcCLDHrUFI+OcXFW3VdV1wGe4p89+AjwKeGRV/aiq7nWumqS+DGSSputWhr00k9mNYa/WtSNt1wJ73YdlfHtk+A7gIZONOInr1w1U1d3AamDdIb6lDHuvaI+b2jt2RFXtPPL3jpHXbhoZ/mFb3vptD+H+98kjR6etqtsZ/h1Gp5+sz/4YCHB+klVJfmeKy5Q0AwxkkqZrBTA/yaJJXr+Fe/bKrLMP8K02/APgQSOvPeI+LLumON7e6wbauWvzgRta08eAn0vyBIbDfO+/D8ufrk31yabW64bRaZM8mGFP5bcmnWLdjKu+XVWvqKpHAr8HnJrksfehdkljZCCTNC1VdQVwKvCvSZ6ZZPskOyZZnOSEdvhuGbAkyUOTPAr4A4bztwAuBJ6eZJ8kOzEcfpuqNcDdDOdhbcyBSV7YzhF7HbAW+FKr/0fAhxnO+Tq/HeIbqyn0yU0MIXf7SWbxAeBlSQ5IsgPwV8CX26HPjUpyVJL57el3GcLfXdNfG0mbk4FM0v3xGuAU4G3AbcB/MVz24uPt9Vcz7Am7CvgcQ6B4F0BVncNwvtVFwAXAWVNdaFXdASwBPt/O53rKJKOeyXDO1ncZztN6YTufbJ2lwBOZ2sn8H1/vOmQfnWq965m0T4BPA6uAbye5Zf0Jq2oF8GfARxjO33sMsHiKy/0F4MtJbgeWA6+tqqunuQ6SNrNUTXXPvyRtXZLsA3wDeERVfa93PZLmLveQSZqT2jllfwCcYRiT1JtX6pc057ST4W9i+MXiYZ3LkSQPWUqSJPXmIUtJkqTODGSSJEmdbdHnkO222261YMGC3mVIkiRt0gUXXHBLVc2b6LUtOpAtWLCAlStX9i5DkiRpk5JcO9lrHrKUJEnqzEAmSZLUmYFMkiSpMwOZJElSZwYySZKkzgxkkiRJnRnIJEmSOjOQSZIkdWYgkyRJ6sxAJkmS1JmBTJIkqbMt+l6WG3PgH72ndwljdcHf/va0prvujU/czJXMLvv8+cXTmu5pb33aZq5kdvn8qz8/renOe/ozNnMls8czPnvetKY75Q8/vpkrmV1e9ebnT2u6JUcfuZkrmV3+9H0f7l2CtnLuIZMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTODGSSJEmdGcgkSZI6M5BJkiR1ZiCTJEnqzEAmSZLUmYFMkiSpMwOZJElSZwYySZKkzrbrXYAkSZpbTjrppN4ljM101809ZJIkSZ0ZyCRJkjobayBLsnOSDyf5RpLLkhycZNck5yS5oj3uMjL+iUmuTHJ5kkPHWZskSdJsMe49ZG8BPlFVjwOeBFwGnACsqKqFwIr2nCT7AYuB/YHDgFOTbDvm+iRJkrobWyBL8jDg6cC/AFTVj6vqNuBwYGkbbSlwRBs+HDijqtZW1dXAlcBB46pPkiRpthjnHrJHA2uAdyf5WpJ3JnkwsEdV3QjQHndv4+8FXD8y/erWJkmStFUbZyDbDvh54J+q6snAD2iHJyeRCdpqg5GS45KsTLJyzZo1m6dSSZKkjsYZyFYDq6vqy+35hxkC2k1J9gRojzePjL/3yPTzgRvWn2lVnVZVi6pq0bx588ZWvCRJ0kwZWyCrqm8D1yf52dZ0CHApsBw4prUdA5zZhpcDi5PskGRfYCFw/rjqkyRJmi3GfaX+VwPvT7I9cBXwMoYQuCzJy4HrgKMAqmpVkmUMoe1O4PiqumvM9UmSJHU31kBWVRcCiyZ46ZBJxl8CLBlnTZIkSbONV+qXJEnqzEAmSZLUmYFMkiSpMwOZJElSZwYySZKkzgxkkiRJnRnIJEmSOjOQSZIkdWYgkyRJ6sxAJkmS1JmBTJIkqTMDmSRJUmcGMkmSpM4MZJIkSZ0ZyCRJkjozkEmSJHVmIJMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTODGSSJEmdGcgkSZI6M5BJkiR1ZiCTJEnqzEAmSZLUmYFMkiSpMwOZJElSZwYySZKkzgxkkiRJnY01kCW5JsnFSS5MsrK17ZrknCRXtMddRsY/McmVSS5Pcug4a5MkSZotZmIP2bOq6oCqWtSenwCsqKqFwIr2nCT7AYuB/YHDgFOTbDsD9UmSJHXV45Dl4cDSNrwUOGKk/YyqWltVVwNXAgfNfHmSJEkza9yBrICzk1yQ5LjWtkdV3QjQHndv7XsB149Mu7q1SZIkbdW2G/P8n1ZVNyTZHTgnyTc2Mm4maKsNRhqC3XEA++yzz+apUpIkqaOx7iGrqhva483ARxkOQd6UZE+A9nhzG301sPfI5POBGyaY52lVtaiqFs2bN2+c5UuSJM2IsQWyJA9O8tB1w8CvApcAy4Fj2mjHAGe24eXA4iQ7JNkXWAicP676JEmSZotxHrLcA/hoknXL+UBVfSLJV4BlSV4OXAccBVBVq5IsAy4F7gSOr6q7xlifJEnSrDC2QFZVVwFPmqD9VuCQSaZZAiwZV02SJEmzkVfqlyRJ6sxAJkmS1JmBTJIkqTMDmSRJUmcGMkmSpM4MZJIkSZ0ZyCRJkjozkEmSJHVmIJMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTODGSSJEmdGcgkSZI6M5BJkiR1ZiCTJEnqzEAmSZLUmYFMkiSpMwOZJElSZwYySZKkzgxkkiRJnRnIJEmSOjOQSZIkdWYgkyRJ6sxAJkmS1JmBTJIkqTMDmSRJUmcGMkmSpM4MZJIkSZ0ZyCRJkjobeyBLsm2SryU5qz3fNck5Sa5oj7uMjHtikiuTXJ7k0HHXJkmSNBvMxB6y1wKXjTw/AVhRVQuBFe05SfYDFgP7A4cBpybZdgbqkyRJ6mqsgSzJfODXgHeONB8OLG3DS4EjRtrPqKq1VXU1cCVw0DjrkyRJmg3GvYfsH4A/Bu4eadujqm4EaI+7t/a9gOtHxlvd2iRJkrZqYwtkSZ4H3FxVF0x1kgnaaoL5HpdkZZKVa9asuV81SpIkzQbj3EP2NOAFSa4BzgCeneR9wE1J9gRojze38VcDe49MPx+4Yf2ZVtVpVbWoqhbNmzdvjOVLkiTNjLEFsqo6sarmV9UChpP1P11VRwPLgWPaaMcAZ7bh5cDiJDsk2RdYCJw/rvokSZJmi+06LPNkYFmSlwPXAUcBVNWqJMuAS4E7geOr6q4O9UmSJM2oGQlkVXUucG4bvhU4ZJLxlgBLZqImSZKk2cIr9UuSJHVmIJMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTOphTIkqyYSpskSZLuu41ehyzJjsCDgN2S7MI995t8GPDIMdcmSZI0J2zqwrC/B7yOIXxdwD2B7HvA28ZXliRJ0tyx0UBWVW8B3pLk1VX11hmqSZIkaU6Z0q2TquqtSZ4KLBidpqreM6a6JEmS5owpBbIk7wUeA1wIrLvhdwEGMkmSpPtpqjcXXwTsV1U1zmIkSZLmoqleh+wS4BHjLESSJGmumuoest2AS5OcD6xd11hVLxhLVZIkSXPIVAPZSeMsQpIkaS6b6q8szxt3IZIkSXPVVH9l+X2GX1UCbA88APhBVT1sXIVJkiTNFVPdQ/bQ0edJjgAOGkdBkiRJc81Uf2V5L1X1MeDZm7cUSZKkuWmqhyxfOPJ0G4brknlNMkmSpM1gqr+yfP7I8J3ANcDhm70aSZKkOWiq55C9bNyFSJIkzVVTOocsyfwkH01yc5KbknwkyfxxFydJkjQXTPWk/ncDy4FHAnsBH29tkiRJup+mGsjmVdW7q+rO9nc6MG+MdUmSJM0ZUw1ktyQ5Osm27e9o4NZxFiZJkjRXTDWQ/Q7wm8C3gRuBIwFP9JckSdoMpnrZizcBx1TVdwGS7Ar8HUNQkyRJ0v0w1T1kP7cujAFU1XeAJ4+nJEmSpLllqoFsmyS7rHvS9pBNde+aJEmSNmKqgezNwBeSvCnJG4EvAH+zsQmS7Jjk/CRfT7Iqyf9p7bsmOSfJFe1xNOidmOTKJJcnOXS6KyVJkrQlmVIgq6r3AL8B3ASsAV5YVe/dxGRrgWdX1ZOAA4DDkjwFOAFYUVULgRXtOUn2AxYD+wOHAacm2fY+r5EkSdIWZsqHHavqUuDS+zB+Abe3pw9of8VwD8xntvalwLnA/27tZ1TVWuDqJFcCBwFfnOoyJUmStkRTPWQ5Le2aZRcCNwPnVNWXgT2q6kaA9rh7G30v4PqRyVe3NkmSpK3aWANZVd1VVQcA84GDkjxhI6NnollsMFJyXJKVSVauWbNmM1UqSZLUz1gD2TpVdRvDocnDgJuS7AnQHm9uo60G9h6ZbD5wwwTzOq2qFlXVonnzvHuTJEna8o0tkCWZl2TnNvxA4DnANxhuUn5MG+0Y4Mw2vBxYnGSHJPsCC4Hzx1WfJEnSbDHOa4ntCSxtv5TcBlhWVWcl+SKwLMnLgeuAowCqalWSZQw/HLgTOL6q7hpjfZIkSbPC2AJZVV3EBFfzr6pbgUMmmWYJsGRcNUmSJM1GM3IOmSRJkiZnIJMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTODGSSJEmdGcgkSZI6M5BJkiR1ZiCTJEnqzEAmSZLUmYFMkiSpMwOZJElSZwYySZKkzgxkkiRJnRnIJEmSOjOQSZIkdWYgkyRJ6sxAJkmS1JmBTJIkqTMDmSRJUmcGMkmSpM4MZJIkSZ0ZyCRJkjozkEmSJHVmIJMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTODGSSJEmdjS2QJdk7yWeSXJZkVZLXtvZdk5yT5Ir2uMvINCcmuTLJ5UkOHVdtkiRJs8k495DdCfxhVT0eeApwfJL9gBOAFVW1EFjRntNeWwzsDxwGnJpk2zHWJ0mSNCuMLZBV1Y1V9dU2/H3gMmAv4HBgaRttKXBEGz4cOKOq1lbV1cCVwEHjqk+SJGm2mJFzyJIsAJ4MfBnYo6puhCG0Abu30fYCrh+ZbHVrW39exyVZmWTlmjVrxlq3JEnSTBh7IEvyEOAjwOuq6nsbG3WCttqgoeq0qlpUVYvmzZu3ucqUJEnqZqyBLMkDGMLY+6vq31rzTUn2bK/vCdzc2lcDe49MPh+4YZz1SZIkzQbj/JVlgH8BLquqvx95aTlwTBs+BjhzpH1xkh2S7AssBM4fV32SJEmzxXZjnPfTgJcCFye5sLX9CXAysCzJy4HrgKMAqmpVkmXApQy/0Dy+qu4aY32SJI3VZUs+3buEsXr8nz67dwlbjbEFsqr6HBOfFwZwyCTTLAGWjKsmSZKk2cgr9UuSJHVmIJMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTODGSSJEmdGcgkSZI6M5BJkiR1ZiCTJEnqzEAmSZLUmYFMkiSpMwOZJElSZwYySZKkzgxkkiRJnRnIJEmSOjOQSZIkdWYgkyRJ6sxAJkmS1JmBTJIkqTMDmSRJUmcGMkmSpM4MZJIkSZ0ZyCRJkjozkEmSJHVmIJMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTOxhbIkrwryc1JLhlp2zXJOUmuaI+7jLx2YpIrk1ye5NBx1SVJkjTbjHMP2enAYeu1nQCsqKqFwIr2nCT7AYuB/ds0pybZdoy1SZIkzRpjC2RV9VngO+s1Hw4sbcNLgSNG2s+oqrVVdTVwJXDQuGqTJEmaTWb6HLI9qupGgPa4e2vfC7h+ZLzVrU2SJGmrN1tO6s8EbTXhiMlxSVYmWblmzZoxlyVJkjR+Mx3IbkqyJ0B7vLm1rwb2HhlvPnDDRDOoqtOqalFVLZo3b95Yi5UkSZoJMx3IlgPHtOFjgDNH2hcn2SHJvsBC4PwZrk2SJKmL7cY14yT/CjwT2C3JauAvgJOBZUleDlwHHAVQVauSLAMuBe4Ejq+qu8ZVmyRJ0mwytkBWVS+e5KVDJhl/CbBkXPVIkiTNVrPlpH5JkqQ5y0AmSZLUmYFMkiSpMwOZJElSZwYySZKkzgxkkiRJnRnIJEmSOjOQSZIkdWYgkyRJ6sxAJkmS1JmBTJIkqTMDmSRJUmcGMkmSpM4MZJIkSZ0ZyCRJkjozkEmSJHVmIJMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTODGSSJEmdGcgkSZI6M5BJkiR1ZiCTJEnqzEAmSZLUmYFMkiSpMwOZJElSZwYySZKkzgxkkiRJnRnIJEmSOpt1gSzJYUkuT3JlkhN61yNJkjRusyqQJdkWeBvwP4D9gBcn2a9vVZIkSeM1qwIZcBBwZVVdVVU/Bs4ADu9ckyRJ0ljNtkC2F3D9yPPVrU2SJGmrlarqXcNPJTkKOLSqfrc9fylwUFW9emSc44Dj2tOfBS6f8UInthtwS+8iZiH7ZWL2y4bsk4nZLxOzXyZmv2xoNvXJo6pq3kQvbDfTlWzCamDvkefzgRtGR6iq04DTZrKoqUiysqoW9a5jtrFfJma/bMg+mZj9MjH7ZWL2y4a2lD6ZbYcsvwIsTLJvku2BxcDyzjVJkiSN1azaQ1ZVdyZ5FfBJYFvgXVW1qnNZkiRJYzWrAhlAVf0H8B+965iGWXcYdZawXyZmv2zIPpmY/TIx+2Vi9suGtog+mVUn9UuSJM1Fs+0cMkmSpDnHQKZpS/KaJJcleX/vWnpJclKS1yd5Y5LnzMDyjphrd69IsiDJJb3rmA2S/EeSne/nPGZNf86mWrYGSY5NckrvOmaj9l77rWlOe/vmrmciBrIZ0G4JtTX6X8Bzq+ol053B1tI3VfXnVfWpGVjUEQy3FdNWIMmUzuPNYJuqem5V3TbmsqSt0QJgwkA21c/huBnIJpDkY0kuSLKqXYiWJLcnWZLk60m+lGSP1v6Y9vwrbS/J7a39mUk+k+QDwMVJ3pTktSPLWJLkNV1WcDNI8nbg0cDyJH+a5F2tD76W5PA2zoIk/5nkq+3vqa39Xn3TcTWmpa3v5Uk+xXBxYpKcnuTINnxykkuTXJTk71rbxt4nZ43M+5Qkx040n9Z/LwD+NsmFSR4zs2t+/yR5cJJ/b5+hS5K8KMmftz65JMlpSdLGPbCN90Xg+M6lb9Ik63ZNkt3a64uSnNuGT2rrejbwnrZX48wkn2jvq79o4y1oe6BPBb4K7L1unhMtr01zYJLz2vbrk0n2HGmfrf25bZJ3tO3t2UkemOQV7X3x9SQfSfIg+Onn7O1tu/LNJM9r7ZP14Vax3U3y22078PUk703y/CRfbtvbT6V9H603zelJ/qlta69K8owM2+nLkpzeYTWmZeRzsP575DHt3/uC9n54XBv/p9vi9nzd3q2TgV9u287fb++ZDyX5OHB2kockWZHhu+ritO+xGVVV/q33B+zaHh8IXAI8HCjg+a39b4A3tOGzgBe34VcCt7fhZwI/APZtzxcAX23D2wD/BTy897rez366huEKyH8FHN3adga+CTwYeBCwY2tfCKycqG+2pD/gQIYQ+SDgYcCVwOuB04EjgV0Z7h6x7gczO0/hfXLWyPxPAY7dyHxOB47s3Q/T7LvfAN4x8nyndZ+19vy9I5+xi4BntOG/BS7pXf801u0aYLf2fBFwbhs+CbgAeGB7fixwY9vOrNvmLGrbjLuBp4zMd91nbqLlPQD4AjCvtb2I4dJBs7Y/2zreCRzQni8DjmZk2wj8JfDqNnw68AmGbehChouJ77iJPtyit7vA/m1bsO69tCuwy8i24XeBN4+8l04Z6aszgDDcE/p7wBNbP1ywrs9n+99G3iMrgIWt7ReBT4+s95Ej00+2rT22vX/Wfd9vBzysDe/GsG3P6DzG/ecesom9JsnXgS8x3DlgIfBjhi9VGN7MC9rwwcCH2vAH1pvP+VV1NUBVXQPcmuTJwK8CX6uqW8e1AjPsV4ETklwInMuwgdyH4QviHUkuZuij0UNtP+2bLcwvAx+tqjuq6ntseOHi7wE/At6Z5IXAHa19Y++TiUw2ny3ZxcBzkvzfJL9cVf8NPKv9T/9i4NnA/kl2Ygig57Xp3tur4PtgonXbmOVV9cOR5+dU1a2t7d+AX2rt11bVl6a4vJ8FngCc0z6LbwDmbwH9eXVVXdiG121bn9D2elwMvIQhlKyzrKrurqorgKuAx7X2DfpwK9nuPhv4cFXdAlBV32G4i80nW//8Effun1EfryFRXAzcVFUXV9XdwCru+Q7bEkz0Hnkq8KH2Xv9nYM9pzPec1p8wBNe/SnIR8CmG+2hvsOdxnGbFcdPZJMkzgecAB1fVHe0ww47AT9obG+AuptZ3P1jv+TsZUvkjgHdthnJniwC/UVX3uq9okpOAm4AnMfyv7EcjL6/fN1uSSa8VU8PFjQ8CDmG408SrGDaok7mTe586sOM05zPrVdU3kxwIPBf463bI7nhgUVVd394vOzK8n7ao6/FMsm6j/7Y7rjfJ+u//9de3JhlvY8v7KLCqqg4eHTfDjwBmc3+uHRm+i2EP1+nAEVX19QyH8J85Ms5kfTVZ+5a+3Z3o8/BW4O+rann7zjppkmnX9e3d3Luf72bL+v5f/z2yB3BbVR0wwbg//dwlCbD9RuY7+vl6CTAPOLCqfpLkGjb83I6Ve8g2tBPw3RbGHgc8ZRPjf4nh8AEMX5wb81HgMOAXGO5GsLX4JPDq9uan/W8Uhr68sf2P7KUMd1/Y0n0W+PV2DsNDgeePvpjkIcBONVzg+HXAAe2lyd4n1wL7Jdmh7ck4ZBPz+T7w0M27SjMjySOBO6rqfcDfAT/fXrqlre+RADWctP7fSdbtJZr2j0ZmyiTrdg3DIW64599+Mr+SZNckD2T44cbnp7G8y4F5SQ5u4zwgyf5bYn8yvMdvTPIANqz3qCTbZDiH8tEM6w2T9+GWvt1dAfxmkocDJNmVYdv6rfb6Mb0K6+h7wNVJjoKf/ujlSe21a7jnc3c4w5Ea2PS2cyfg5hbGngU8arNXvQlbUkKeKZ8AXtl2W17O8EW6Ma8D3pfkD4F/ByY9VFFVP07yGYZkf9dmqnc2eBPwD8BFLZRdAzwPOBX4SPvQfIYte68YAFX11SQfBC5kCFP/ud4oDwXOTLJuT8/vt/bXMcH7pO0ZWsZwjs8VwNc2MZ8zGA4Dv4bhPIn/2uwrOT5PZPhBwt3AT4D/yfDFeTHDe+YrI+O+DHhXkjvYMr5EJ1q3BwL/kuRPgC9vYvrPMRxKfCzwgapamWTBfVle274cCfxjC/fbMXwuV7Hl9eefMfTZtQzvj9Ev0suB8xj2kryyqn7U/i+4QR/Clr/drapVSZYA5yW5i2EbcRLD4bpvMXxH7duxxF5eAvxTkjcwhK4zgK8D72DYdp7PEGbXfe9cBNzZTkc6HfjuevN7P/DxJCsZtu/fGPcKrM8r9d9PGX7988OqqiSLGU7cnvDXGUm2Yfi11FHt/AfNEfflfaK5pR2SW1RVr+pdy2yX4deBZ1XVh9drP5ZJ+tDtrrYU7iG7/w4ETml7hm4DfmeikTJczPMshhPC3SjMPVN6n0jafNzuakviHjJJkqTOPKlfkiSpMwOZJElSZwYySZKkzgxkkjSBJAckee7I8xckOaFnTZK2Xp7UL0kT8HIUkmaSe8gkbRWSHJ3k/CQXJvnnJNsmub3d7/GCJJ9KclCSc5NcleQFbbodk7w7ycVJvpbkWUm2B94IvKjN70VJjk1ySpvmUUlWJLmoPe7T2k9P8o9JvtCWcWS/HpG0JTGQSdriJXk88CLgae3+dncxXMn7wcC5VXUgw61T/hL4FeDXGQIXDPfTpKqeCLwYWMqwbfxz4INVdUBVfXC9RZ4CvKeqfo7hCt//OPLangw3B38ecPLmXVNJWysvDCtpa3AIw8V3v9Juo/NA4Gbgxwy3Q4PhFjxr273qLgYWtPZfYrhZM1X1jSTXAj+zieUdDLywDb8X+JuR1z7W7t96aZI97s9KSZo7DGSStgYBllbVifdqTF5f95woezewFqCq7k6y3ci099foybhr16tLkjbJQ5aStgYrgCOT7A6QZNckj5ritJ9lOLxJkp8B9mG4gfX3ufdNrUd9AVjchl/CcGNrSZo2A5mkLV5VXQq8ATg7yUXAOQznck3FqcC27TDmB4Fjq2ot8Blgv3Un9a83zWuAl7VlvRR47eZYD0lzl5e9kCRJ6sw9ZJIkSZ0ZyCRJkjozkEmSJHVmIJMkSerMQCZJktSZgUySJKkzA5kkSVJnBjJJkqTO/j8aGvhnIjYXbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#distribution of the data\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.countplot(data = df_all, x=\"emotion\")\n",
    "plt.title(\" Count by Emotions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68982b6",
   "metadata": {},
   "source": [
    "## Calm is only present in RAVDESS and not in TESS and SAVEE, we will drop this and we will only predict 7 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20c648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all[df_all[\"emotion\"] != 'calm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce00ad9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4528, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#less calm\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d3b860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('./dataset/all_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f5dad6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>emotion</th>\n",
       "      <th>audio</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./raw_source/RAVDESS/Actor_16/03-01-05-01-02-0...</td>\n",
       "      <td>angry</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./raw_source/RAVDESS/Actor_16/03-01-06-01-02-0...</td>\n",
       "      <td>fear</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./raw_source/RAVDESS/Actor_16/03-01-06-02-01-0...</td>\n",
       "      <td>fear</td>\n",
       "      <td>[3.0036153e-05, 2.7443759e-05, 9.890327e-07, 6...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./raw_source/RAVDESS/Actor_16/03-01-05-02-01-0...</td>\n",
       "      <td>angry</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./raw_source/RAVDESS/Actor_16/03-01-07-01-01-0...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>ravdess</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  emotion  \\\n",
       "0  ./raw_source/RAVDESS/Actor_16/03-01-05-01-02-0...    angry   \n",
       "1  ./raw_source/RAVDESS/Actor_16/03-01-06-01-02-0...     fear   \n",
       "2  ./raw_source/RAVDESS/Actor_16/03-01-06-02-01-0...     fear   \n",
       "3  ./raw_source/RAVDESS/Actor_16/03-01-05-02-01-0...    angry   \n",
       "4  ./raw_source/RAVDESS/Actor_16/03-01-07-01-01-0...  disgust   \n",
       "\n",
       "                                               audio   source  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ravdess  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ravdess  \n",
       "2  [3.0036153e-05, 2.7443759e-05, 9.890327e-07, 6...  ravdess  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ravdess  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ravdess  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b16224",
   "metadata": {},
   "source": [
    "### 02.  FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ca19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "919b806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def librosa_features(data):\n",
    "    \n",
    "    '''this will create an array of some librosa features\n",
    "    (e.g. zero_crossing_rate, root mean square energy, spectral centroid and rollfoof,\n",
    "        chroma_stft, mfcc, rms, melspectrogram)\n",
    "    concatenated for each audio'''\n",
    "    \n",
    "    \n",
    "    result = np.array([])\n",
    "    \n",
    "   \n",
    "    # Root Mean Square Value (one column, the average )\n",
    "    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
    "    result = np.hstack((result, rms)) # add as column \n",
    "\n",
    "    \n",
    "     # Spectral Centroid (one column, the average )\n",
    "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, spectral_centroid)) # stacking horizontally\n",
    "    \n",
    "    \n",
    "        \n",
    "     # Spectral Rolloff (one column, the average )\n",
    "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=data, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, spectral_rolloff)) # add as column \n",
    "    \n",
    "        \n",
    "    \n",
    "    # Zero Crossing Rate (one column, the average )\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
    "    result=np.hstack((result, zcr)) # add as column \n",
    "    \n",
    "\n",
    "    \n",
    "    # Chroma_stft (12 columns)\n",
    "    stft = np.abs(librosa.stft(data))\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma_stft)) # stacking horizontally\n",
    "\n",
    "    \n",
    "    # MFCC  (40 columns)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "    result = np.hstack((result, mfcc)) # stacking horizontally\n",
    "      \n",
    "    \n",
    "    # MelSpectogram (128 columns)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate, n_fft=2048, hop_length=512, n_mels=128).T, axis=0)\n",
    "    result = np.hstack((result, mel)) # stacking horizontally\n",
    "    \n",
    "        \n",
    "    return result\n",
    "\n",
    "def get_basic_features(audio):\n",
    "    ''' get librosa features only for the test dataset '''\n",
    "        \n",
    "    #Trim leading and trailing silence from an audio signal.\n",
    "    yt, index = librosa.effects.trim(audio)\n",
    "    \n",
    "    \n",
    "    #librosa features\n",
    "    res1 = librosa_features(yt)\n",
    "\n",
    "    \n",
    "    return res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3ca01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##functions for data augmentation\n",
    "\n",
    "#default values, can change accordingly\n",
    "v_random_noise = 0.030\n",
    "v_stretch_rate = 0.75\n",
    "v_shift_low = -5\n",
    "v_shift_high = 5\n",
    "v_pitch_factor = 0.8\n",
    "\n",
    "def add_noise(data):\n",
    "    noise_amp = v_random_noise*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def add_stretch(data, rate=v_stretch_rate):\n",
    "    return librosa.effects.time_stretch(data, rate=rate)\n",
    "\n",
    "def add_pitch(data, sampling_rate, pitch_factor= v_pitch_factor):\n",
    "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1a7e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_extra(audio):\n",
    "    \n",
    "    ''' get librosa features plus data augmentation for the train dataset '''\n",
    "        \n",
    "    #Trim leading and trailing silence from an audio signal\n",
    "    yt, index = librosa.effects.trim(audio)\n",
    "    \n",
    "    # only libroras features\n",
    "    res1 = librosa_features(yt)\n",
    "    result = np.array(res1)\n",
    "    \n",
    "    ### with data augmentation\n",
    "    \n",
    "    # data with noise\n",
    "    noise_data = add_noise(yt)\n",
    "    res2 = librosa_features(noise_data)\n",
    "    result = np.vstack((result, res2)) # as new record\n",
    "    \n",
    "    # data with stretching and pitching\n",
    "    new_data = add_stretch(yt)\n",
    "    data_stretch_pitch = add_pitch(new_data, sample_rate)\n",
    "    res3 = librosa_features(data_stretch_pitch)\n",
    "    result = np.vstack((result, res3)) # as new record\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34223eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "train,test = train_test_split(df_all, random_state=0, shuffle=True, stratify=df_all['emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce9b1b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fear         0.143993\n",
       "happy        0.143993\n",
       "surprised    0.143993\n",
       "sad          0.143993\n",
       "angry        0.143993\n",
       "disgust      0.143993\n",
       "neutral      0.136042\n",
       "Name: emotion, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate the distribution of data is even for train and test for each emotion\n",
    "train[\"emotion\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afcd3aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disgust      0.143993\n",
       "fear         0.143993\n",
       "happy        0.143993\n",
       "sad          0.143993\n",
       "angry        0.143993\n",
       "surprised    0.143993\n",
       "neutral      0.136042\n",
       "Name: emotion, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate the distribution of data is even for train and test for each emotion\n",
    "test[\"emotion\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9122542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3396, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to save the no of records for train\n",
    "shape_train = train.shape\n",
    "shape_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21e7c1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1132, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to save the no of records for test\n",
    "shape_test = test.shape\n",
    "shape_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ea1d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_withAugmentation(df):\n",
    "    \n",
    "    ''' the number of records will be times three, we are adding two records, one with noise, the other with pitch'''\n",
    "    librosa_X, librosa_y, librosa_f = [], [], []\n",
    "    \n",
    "    for x, row in df.iterrows():\n",
    "    \n",
    "        #librosa with  noise, stretching\n",
    "        feat = get_features_extra(row[\"audio\"])\n",
    "    \n",
    "        for f in feat:\n",
    "            librosa_X.append(f)\n",
    "            librosa_y.append(row[\"emotion\"])\n",
    "            librosa_f.append(row[\"file\"])\n",
    "    \n",
    "    df_feature = pd.DataFrame(librosa_X)\n",
    "    df_feature['label'] = librosa_y\n",
    "    df_feature['file'] = librosa_f\n",
    "\n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38d9a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_noAugmentation(df):\n",
    "    \n",
    "    ''' just the librosa features '''\n",
    "    \n",
    "    librosa_X, librosa_y, librosa_f = [], [], []\n",
    "    \n",
    "    for x,row in df.iterrows():\n",
    "        \n",
    "        feat = get_basic_features(row[\"audio\"])\n",
    "\n",
    "        librosa_X.append(feat)\n",
    "        librosa_y.append(row[\"emotion\"])\n",
    "        librosa_f.append(row[\"file\"])\n",
    "    \n",
    "    df_feature = pd.DataFrame(librosa_X)\n",
    "    df_feature['label'] = librosa_y\n",
    "    df_feature['file'] = librosa_f\n",
    "    \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b602feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction for train dataset with augmentation\n",
    "train_proc = train_withAugmentation(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "074fa03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train after processing:  (10188, 186) Expected: 30564\n"
     ]
    }
   ],
   "source": [
    "#no of records should be x3\n",
    "print('Train after processing: ', train_proc.shape, 'Expected:', train_proc.shape[0]*3)\n",
    "\n",
    "#testing\n",
    "assert train_proc.shape[0] == shape_train[0]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0389ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction for test dataset\n",
    "test_proc = test_noAugmentation(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1e08a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010871</td>\n",
       "      <td>2547.460692</td>\n",
       "      <td>4225.225761</td>\n",
       "      <td>0.146462</td>\n",
       "      <td>0.350376</td>\n",
       "      <td>0.489627</td>\n",
       "      <td>0.388288</td>\n",
       "      <td>0.277398</td>\n",
       "      <td>0.330770</td>\n",
       "      <td>0.440719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>1.770702e-04</td>\n",
       "      <td>1.284800e-04</td>\n",
       "      <td>1.070036e-04</td>\n",
       "      <td>9.785273e-05</td>\n",
       "      <td>7.668910e-05</td>\n",
       "      <td>2.502960e-05</td>\n",
       "      <td>1.583275e-06</td>\n",
       "      <td>neutral</td>\n",
       "      <td>./raw_source/TESS/OAF_neutral/OAF_sub_neutral.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014300</td>\n",
       "      <td>1825.103691</td>\n",
       "      <td>2837.405799</td>\n",
       "      <td>0.099402</td>\n",
       "      <td>0.435393</td>\n",
       "      <td>0.508717</td>\n",
       "      <td>0.566287</td>\n",
       "      <td>0.620762</td>\n",
       "      <td>0.594975</td>\n",
       "      <td>0.504975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>4.537473e-04</td>\n",
       "      <td>4.394072e-04</td>\n",
       "      <td>3.523740e-04</td>\n",
       "      <td>2.447775e-04</td>\n",
       "      <td>1.527458e-04</td>\n",
       "      <td>4.183541e-05</td>\n",
       "      <td>2.718440e-06</td>\n",
       "      <td>disgust</td>\n",
       "      <td>./raw_source/TESS/OAF_disgust/OAF_knock_disgus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002364</td>\n",
       "      <td>3178.091805</td>\n",
       "      <td>5857.320286</td>\n",
       "      <td>0.287401</td>\n",
       "      <td>0.650888</td>\n",
       "      <td>0.591952</td>\n",
       "      <td>0.608699</td>\n",
       "      <td>0.609804</td>\n",
       "      <td>0.553792</td>\n",
       "      <td>0.563674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>9.197745e-05</td>\n",
       "      <td>1.416200e-04</td>\n",
       "      <td>1.751091e-04</td>\n",
       "      <td>3.004984e-04</td>\n",
       "      <td>1.877091e-04</td>\n",
       "      <td>2.995609e-05</td>\n",
       "      <td>2.822386e-06</td>\n",
       "      <td>fear</td>\n",
       "      <td>./raw_source/RAVDESS/Actor_06/03-01-06-01-01-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127967</td>\n",
       "      <td>1101.501296</td>\n",
       "      <td>1980.794205</td>\n",
       "      <td>0.027615</td>\n",
       "      <td>0.592087</td>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.529101</td>\n",
       "      <td>0.503935</td>\n",
       "      <td>0.516974</td>\n",
       "      <td>0.592902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>9.104003e-07</td>\n",
       "      <td>9.869351e-07</td>\n",
       "      <td>9.132608e-07</td>\n",
       "      <td>9.256651e-07</td>\n",
       "      <td>3.880744e-07</td>\n",
       "      <td>1.712170e-07</td>\n",
       "      <td>4.390066e-08</td>\n",
       "      <td>happy</td>\n",
       "      <td>./raw_source/Savee/JE/h13.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006590</td>\n",
       "      <td>2747.088848</td>\n",
       "      <td>5786.171989</td>\n",
       "      <td>0.182969</td>\n",
       "      <td>0.713597</td>\n",
       "      <td>0.755569</td>\n",
       "      <td>0.742611</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.663825</td>\n",
       "      <td>0.642817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>1.087833e-04</td>\n",
       "      <td>9.435938e-05</td>\n",
       "      <td>1.028792e-04</td>\n",
       "      <td>1.043497e-04</td>\n",
       "      <td>7.786060e-05</td>\n",
       "      <td>2.384895e-05</td>\n",
       "      <td>2.291553e-06</td>\n",
       "      <td>sad</td>\n",
       "      <td>./raw_source/RAVDESS/Actor_11/03-01-04-02-01-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0            1            2         3         4         5         6  \\\n",
       "0  0.010871  2547.460692  4225.225761  0.146462  0.350376  0.489627  0.388288   \n",
       "1  0.014300  1825.103691  2837.405799  0.099402  0.435393  0.508717  0.566287   \n",
       "2  0.002364  3178.091805  5857.320286  0.287401  0.650888  0.591952  0.608699   \n",
       "3  0.127967  1101.501296  1980.794205  0.027615  0.592087  0.558594  0.529101   \n",
       "4  0.006590  2747.088848  5786.171989  0.182969  0.713597  0.755569  0.742611   \n",
       "\n",
       "          7         8         9  ...       176           177           178  \\\n",
       "0  0.277398  0.330770  0.440719  ...  0.000159  1.770702e-04  1.284800e-04   \n",
       "1  0.620762  0.594975  0.504975  ...  0.000656  4.537473e-04  4.394072e-04   \n",
       "2  0.609804  0.553792  0.563674  ...  0.000046  9.197745e-05  1.416200e-04   \n",
       "3  0.503935  0.516974  0.592902  ...  0.000002  9.104003e-07  9.869351e-07   \n",
       "4  0.696970  0.663825  0.642817  ...  0.000117  1.087833e-04  9.435938e-05   \n",
       "\n",
       "            179           180           181           182           183  \\\n",
       "0  1.070036e-04  9.785273e-05  7.668910e-05  2.502960e-05  1.583275e-06   \n",
       "1  3.523740e-04  2.447775e-04  1.527458e-04  4.183541e-05  2.718440e-06   \n",
       "2  1.751091e-04  3.004984e-04  1.877091e-04  2.995609e-05  2.822386e-06   \n",
       "3  9.132608e-07  9.256651e-07  3.880744e-07  1.712170e-07  4.390066e-08   \n",
       "4  1.028792e-04  1.043497e-04  7.786060e-05  2.384895e-05  2.291553e-06   \n",
       "\n",
       "     label                                               file  \n",
       "0  neutral  ./raw_source/TESS/OAF_neutral/OAF_sub_neutral.wav  \n",
       "1  disgust  ./raw_source/TESS/OAF_disgust/OAF_knock_disgus...  \n",
       "2     fear  ./raw_source/RAVDESS/Actor_06/03-01-06-01-01-0...  \n",
       "3    happy                      ./raw_source/Savee/JE/h13.wav  \n",
       "4      sad  ./raw_source/RAVDESS/Actor_11/03-01-04-02-01-0...  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e48209d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1132, 186)\n"
     ]
    }
   ],
   "source": [
    "#there should be no changes in the no of records\n",
    "print(test_proc.shape)\n",
    "\n",
    "#testing\n",
    "assert test_proc.shape[0] == shape_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddaf282",
   "metadata": {},
   "source": [
    "### Train and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "963250c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save to file for MODELLING\n",
    "\n",
    "train_proc.to_csv(\"./dataset/train.csv\")\n",
    "test_proc.to_csv(\"./dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3aca3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
